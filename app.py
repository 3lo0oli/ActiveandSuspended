import streamlit as st
import httpx
from bs4 import BeautifulSoup

# Ø¥Ø¹Ø¯Ø§Ø¯ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
st.set_page_config(page_title="ÙØ­Øµ Ø­Ø³Ø§Ø¨Ø§Øª Reddit", page_icon="ğŸ”", layout="wide")
st.title("ğŸ” Ø£Ø¯Ø§Ø© ÙØ­Øµ Ø­Ø§Ù„Ø© Ø­Ø³Ø§Ø¨Ø§Øª Reddit")
st.markdown("""
ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø§Ù„Ø© Ø­Ø³Ø§Ø¨Ø§Øª Reddit (Ù†Ø´Ø·/Ù…ÙˆÙ‚ÙˆÙ/ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯) Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ù…Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹.
""")

# Ø£Ø³Ù„ÙˆØ¨ CSS Ù…Ø®ØµØµ
st.markdown("""
<style>
    .stTextArea textarea {
        min-height: 150px;
    }
    .stProgress > div > div > div {
        background-color: #FF4B4B;
    }
    .st-b7 {
        color: white;
    }
</style>
""", unsafe_allow_html=True)

# Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
def normalize_url(url):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø¯Ø®Ù„Ø© Ù„ØªÙƒÙˆÙ† Ø¨ØµÙŠØºØ© ØµØ­ÙŠØ­Ø©"""
    url = url.strip()
    if not url.startswith(("http://", "https://")):
        if not url.startswith("u/"):
            url = "u/" + url
        url = "https://www.reddit.com/" + url
    return url.replace("www.reddit.com", "old.reddit.com").rstrip("/")

def check_reddit_status_httpx(url):
    """ÙØ­Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø³Ø§Ø¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… HTTPX"""
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    
    try:
        response = httpx.get(url, headers=headers, timeout=15, follow_redirects=True)
        html = response.text.lower()
        
        if response.status_code == 404 or "nobody on reddit goes by that name" in html:
            return "âŒ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"
        elif "this account has been suspended" in html or "suspended" in html:
            return "ğŸš« Ù…ÙˆÙ‚ÙˆÙ"
        elif "page not found" in html:
            return "âŒ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"
        else:
            return "âœ… Ù†Ø´Ø·"
    except httpx.RequestError:
        return "âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„"
    except Exception as e:
        return f"âš ï¸ Ø®Ø·Ø£: {str(e)}"

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
with st.expander("ğŸ¯ ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…", expanded=True):
    st.markdown("""
    - Ø£Ø¯Ø®Ù„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø£Ùˆ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· (Ø³Ø·Ø± Ù„ÙƒÙ„ Ø­Ø³Ø§Ø¨)
    - Ø£Ù…Ø«Ù„Ø©:
        ```
        u/username
        https://www.reddit.com/user/username
        username
        ```
    """)

user_input = st.text_area(
    "âœï¸ Ø£Ø¯Ø®Ù„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø£Ùˆ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·:",
    placeholder="Ø£Ø¯Ø®Ù„ Ù‡Ù†Ø§...\nÙ…Ø«Ø§Ù„:\nu/username\nhttps://www.reddit.com/user/username",
    help="ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¯Ø®Ø§Ù„ Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø¹Ø¯Ø© Ø­Ø³Ø§Ø¨Ø§Øª (Ø³Ø·Ø± Ù„ÙƒÙ„ Ø­Ø³Ø§Ø¨)"
)

# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
if st.button("ğŸ” ØªØ­Ù‚Ù‚ Ø§Ù„Ø¢Ù†", type="primary"):
    if user_input.strip():
        links = [line.strip() for line in user_input.strip().splitlines() if line.strip()]
        results = []
        stats = {"âœ… Ù†Ø´Ø·": 0, "ğŸš« Ù…ÙˆÙ‚ÙˆÙ": 0, "âŒ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯": 0, "âš ï¸ Ø£Ø®Ø·Ø§Ø¡": 0}
        
        with st.spinner("Ø¬Ø§Ø±Ù Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª..."):
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i, url in enumerate(links):
                try:
                    normalized_url = normalize_url(url)
                    status = check_reddit_status_httpx(normalized_url)
                    results.append((normalized_url, status))
                    stats[status.split()[0]] += 1  # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
                    
                    # ØªØ­Ø¯ÙŠØ« Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù…
                    progress = (i + 1) / len(links)
                    progress_bar.progress(progress)
                    status_text.text(f"Ø¬Ø§Ø±Ù Ù…Ø¹Ø§Ù„Ø¬Ø© {i+1}/{len(links)} - {url[:30]}...")
                except Exception as e:
                    results.append((url, f"âš ï¸ Ø®Ø·Ø£: {str(e)}"))
                    stats["âš ï¸ Ø£Ø®Ø·Ø§Ø¡"] += 1
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        st.success("âœ… ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„ØªØ­Ù‚Ù‚!")
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø©", stats["âœ… Ù†Ø´Ø·"])
        col2.metric("Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ø§Ù„Ù…ÙˆÙ‚ÙˆÙØ©", stats["ğŸš« Ù…ÙˆÙ‚ÙˆÙ"])
        col3.metric("Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©", stats["âŒ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"])
        col4.metric("Ø§Ù„Ø£Ø®Ø·Ø§Ø¡", stats["âš ï¸ Ø£Ø®Ø·Ø§Ø¡"])
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©
        st.subheader("ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©:")
        for url, status in results:
            st.markdown(f"- {status}: [{url}]({url})")
        
        # Ø²Ø± Ù†Ø³Ø® Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        result_text = "\n".join([f"{status}: {url}" for url, status in results])
        st.download_button(
            label="ğŸ“‹ Ù†Ø³Ø® Ø§Ù„Ù†ØªØ§Ø¦Ø¬",
            data=result_text,
            file_name="reddit_status_results.txt",
            mime="text/plain"
        )
    else:
        st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø±ÙˆØ§Ø¨Ø· Ø£Ùˆ Ø£Ø³Ù…Ø§Ø¡ Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø£ÙˆÙ„Ø§Ù‹")

# ØªØ°ÙŠÙŠÙ„ Ø§Ù„ØµÙØ­Ø©
st.markdown("---")
st.markdown("""
**Ù…Ù„Ø§Ø­Ø¸Ø§Øª:**
- ÙŠØ¹Ù…Ù„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ù…Ù† Reddit (old.reddit.com)
- Ù‚Ø¯ ØªØ¸Ù‡Ø± Ø¨Ø¹Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ØºÙŠØ± Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø© Ø¨Ø³Ø¨Ø¨ ØªØºÙŠÙŠØ±Ø§Øª ÙÙŠ ÙˆØ§Ø¬Ù‡Ø© Reddit
""")
