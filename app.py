import streamlit as st
import httpx
import re
from urllib.parse import urlparse
from bs4 import BeautifulSoup

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
st.set_page_config(
    page_title="Ø£Ø¯Ø§Ø© Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„ÙØ¹Ù„ÙŠ Ù…Ù† Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª",
    page_icon="ğŸŒ",
    layout="wide"
)

# CSS Ù…Ø®ØµØµ
st.markdown("""
<style>
    .header {
        text-align: center;
        color: #2b5876;
        margin-bottom: 30px;
    }
    .result-box {
        padding: 20px;
        border-radius: 8px;
        margin: 20px 0;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }
    .active { border-left: 5px solid #4CAF50; background-color: #e8f5e9; }
    .suspended { border-left: 5px solid #f44336; background-color: #ffebee; }
    .not-found { border-left: 5px solid #FF9800; background-color: #fff3e0; }
    .deleted { border-left: 5px solid #607d8b; background-color: #eceff1; }
    .unknown { border-left: 5px solid #9e9e9e; background-color: #f5f5f5; }
    .stButton>button {
        background-color: #FF4500;
        color: white;
        font-weight: bold;
        border: none;
        padding: 0.5rem 1rem;
        border-radius: 0.5rem;
        width: 100%;
    }
    .tab-content {
        padding: 20px;
        background: #f9f9f9;
        border-radius: 8px;
        margin-top: 10px;
    }
    .screenshot {
        max-width: 100%;
        border: 1px solid #ddd;
        border-radius: 4px;
        margin-top: 10px;
    }
</style>
""", unsafe_allow_html=True)

# Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
st.markdown("<h1 class='header'>ğŸŒ Ø£Ø¯Ø§Ø© Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„ÙØ¹Ù„ÙŠ Ù…Ù† Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª</h1>", unsafe_allow_html=True)

# ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ù…Ù†ØµØ§Øª
platform = st.selectbox(
    "Ø§Ø®ØªØ± Ø§Ù„Ù…Ù†ØµØ©:",
    ["Reddit", "Facebook", "Twitter", "Instagram", "LinkedIn"],
    index=0
)

# Ø¯Ø§Ù„Ø© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·
def extract_username(url, platform):
    try:
        if not url:
            return None
            
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
        url = url.strip().strip("/").replace("https://", "").replace("http://", "")
        
        if platform == "Reddit":
            if "reddit.com" not in url:
                return url.split("/")[0].replace("u/", "").replace("@", "")
            return url.split("/user/")[-1].split("/")[0] if "/user/" in url else url.split("/u/")[-1].split("/")[0]
        
        elif platform == "Facebook":
            if "facebook.com" not in url:
                return url.split("/")[0].split("?")[0]
            return url.split("facebook.com/")[-1].split("/")[0].split("?")[0]
        
        elif platform == "Twitter":
            if "twitter.com" not in url and "x.com" not in url:
                return url.split("/")[0].replace("@", "")
            return url.split("twitter.com/")[-1].split("/")[0].split("?")[0] if "twitter.com" in url else url.split("x.com/")[-1].split("/")[0].split("?")[0]
        
        elif platform == "Instagram":
            if "instagram.com" not in url:
                return url.split("/")[0].replace("@", "")
            return url.split("instagram.com/")[-1].split("/")[0].split("?")[0]
        
        elif platform == "LinkedIn":
            if "linkedin.com" not in url:
                return url.split("/")[0].replace("@", "")
            return url.split("linkedin.com/in/")[-1].split("/")[0].split("?")[0]
    
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {str(e)}")
        return None

# Ø¯Ø§Ù„Ø© Ù„ÙØ­Øµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙØ¹Ù„ÙŠ Ù„Ù„ØµÙØ­Ø©
def check_page_content(url, platform):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
        "Accept-Language": "en-US,en;q=0.9"
    }
    
    try:
        with httpx.Client(follow_redirects=True, timeout=20) as client:
            response = client.get(url, headers=headers)
            html = response.text.lower()
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø®ÙÙŠØ© ÙˆØºÙŠØ± Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ©
            for script in soup(["script", "style", "noscript", "meta", "link"]):
                script.decompose()
            
            visible_text = soup.get_text().lower()
            
            if platform == "Reddit":
                if response.status_code == 404 or "page not found" in visible_text:
                    return "âŒ Ø§Ù„Ø­Ø³Ø§Ø¨ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯", "not-found"
                
                if ("suspended" in visible_text or 
                    "content unavailable" in visible_text or
                    "this account has been suspended" in visible_text):
                    return "ğŸ”´ Ø§Ù„Ø­Ø³Ø§Ø¨ Ù…ÙˆÙ‚ÙˆÙ", "suspended"
                
                if response.status_code == 200 and ("karma" in html or "cake day" in html):
                    return "ğŸŸ¢ Ø§Ù„Ø­Ø³Ø§Ø¨ Ù†Ø´Ø·", "active"
            
            elif platform == "Facebook":
                if response.status_code == 404 or "page not found" in visible_text:
                    return "âŒ Ø§Ù„Ø­Ø³Ø§Ø¨ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯", "not-found"
                
                if ("content isn't available" in visible_text or 
                    "this page isn't available" in visible_text or
                    "ØªÙ… Ø­Ø¸Ø± Ù‡Ø°Ù‡ Ø§Ù„ØµÙØ­Ø©" in visible_text):
                    return "ğŸ”´ Ø§Ù„Ø­Ø³Ø§Ø¨ Ù…Ø­Ø¸ÙˆØ±", "suspended"
                
                if response.status_code == 200 and ("timeline" in html or "posts" in html):
                    return "ğŸŸ¢ Ø§Ù„Ø­Ø³Ø§Ø¨ Ù†Ø´Ø·", "active"
            
            elif platform == "Twitter":
                if response.status_code == 404 or "page doesn't exist" in visible_text:
                    return "âŒ Ø§Ù„Ø­Ø³Ø§Ø¨ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯", "not-found"
                
                if ("account suspended" in visible_text or 
                    "Ù‡Ø°Ø§ Ø§Ù„Ø­Ø³Ø§Ø¨ Ù…Ø¹Ù„Ù‚" in visible_text or
                    "ã“ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¯åœæ­¢ã•ã‚Œã¦ã„ã¾ã™" in visible_text):
                    return "ğŸ”´ Ø§Ù„Ø­Ø³Ø§Ø¨ Ù…ÙˆÙ‚ÙˆÙ", "suspended"
                
                if response.status_code == 200 and ("tweets" in html or "following" in html):
                    return "ğŸŸ¢ Ø§Ù„Ø­Ø³Ø§Ø¨ Ù†Ø´Ø·", "active"
            
            elif platform == "Instagram":
                if response.status_code == 404 or "page not found" in visible_text:
                    return "âŒ Ø§Ù„Ø­Ø³Ø§Ø¨ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯", "not-found"
                
                if ("sorry, this page isn't available" in visible_text or 
                    "Ø¹Ø°Ø±Ù‹Ø§ØŒ Ù‡Ø°Ù‡ Ø§Ù„ØµÙØ­Ø© ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©" in visible_text):
                    return "ğŸ”´ Ø§Ù„Ø­Ø³Ø§Ø¨ Ù…Ø­Ø¸ÙˆØ±", "suspended"
                
                if response.status_code == 200 and ("posts" in html or "followers" in html):
                    return "ğŸŸ¢ Ø§Ù„Ø­Ø³Ø§Ø¨ Ù†Ø´Ø·", "active"
            
            elif platform == "LinkedIn":
                if response.status_code == 404 or "page not found" in visible_text:
                    return "âŒ Ø§Ù„Ø­Ø³Ø§Ø¨ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯", "not-found"
                
                if ("this profile is unavailable" in visible_text or 
                    "Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ØªØ§Ø­" in visible_text):
                    return "ğŸ”´ Ø§Ù„Ø­Ø³Ø§Ø¨ Ù…Ø­Ø¸ÙˆØ±", "suspended"
                
                if response.status_code == 200 and ("experience" in html or "education" in html):
                    return "ğŸŸ¢ Ø§Ù„Ø­Ø³Ø§Ø¨ Ù†Ø´Ø·", "active"
            
            return "âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø­Ø§Ù„Ø©", "unknown"
    
    except httpx.TimeoutException:
        return "âš ï¸ Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ø·Ù„Ø¨", "unknown"
    except Exception as e:
        return f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {str(e)}", "unknown"

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
user_input = st.text_input(
    f"Ø£Ø¯Ø®Ù„ Ø±Ø§Ø¨Ø· Ø§Ù„Ø­Ø³Ø§Ø¨ Ø£Ùˆ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ù„Ù‰ {platform}:",
    placeholder=f"Ù…Ø«Ø§Ù„: username Ø£Ùˆ https://{'reddit.com' if platform == 'Reddit' else 'facebook.com' if platform == 'Facebook' else 'twitter.com' if platform == 'Twitter' else 'instagram.com' if platform == 'Instagram' else 'linkedin.com'}/username"
)

check_button = st.button("ØªØ­Ù‚Ù‚ Ø§Ù„Ø¢Ù†")

# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØªÙŠØ¬Ø©
if check_button:
    if user_input:
        with st.spinner("Ø¬Ø§Ø±ÙŠ ÙØªØ­ Ø§Ù„Ø±Ø§Ø¨Ø· ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙØ¹Ù„ÙŠ..."):
            username = extract_username(user_input, platform)
            
            if username:
                if platform == "Reddit":
                    url = f"https://www.reddit.com/user/{username}/"
                elif platform == "Facebook":
                    url = f"https://www.facebook.com/{username}/"
                elif platform == "Twitter":
                    url = f"https://twitter.com/{username}/"
                elif platform == "Instagram":
                    url = f"https://instagram.com/{username}/"
                elif platform == "LinkedIn":
                    url = f"https://linkedin.com/in/{username}/"
                
                status, status_class = check_page_content(url, platform)
                
                # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø©
                st.markdown(
                    f"""
                    <div class="result-box {status_class}">
                        <h3>{status}</h3>
                        <p><strong>Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:</strong> {username}</p>
                        <p><strong>Ø±Ø§Ø¨Ø· Ø§Ù„Ø­Ø³Ø§Ø¨:</strong> <a href="{url}" target="_blank">{url}</a></p>
                    </div>
                    """,
                    unsafe_allow_html=True
                )
                
                # Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
                with st.expander("ØªÙØ§ØµÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠØ©", expanded=False):
                    st.write(f"**ÙƒÙˆØ¯ Ø§Ù„Ø­Ø§Ù„Ø©:** {status.split(' ')[0]}")
                    st.write(f"**Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø°ÙŠ ØªÙ… ÙØ­ØµÙ‡:** [{url}]({url})")
                    
                    if status_class == "active":
                        st.success("ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø³Ø§Ø¨ ÙˆÙ‡Ùˆ Ù†Ø´Ø·. ÙŠÙ…ÙƒÙ†Ùƒ Ø²ÙŠØ§Ø±Ø© Ø§Ù„Ø±Ø§Ø¨Ø· Ø£Ø¹Ù„Ø§Ù‡ Ù„Ù…Ø´Ø§Ù‡Ø¯Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰.")
                    elif status_class == "suspended":
                        st.error("Ø§Ù„Ø­Ø³Ø§Ø¨ Ù…ÙˆÙ‚ÙˆÙ Ø£Ùˆ Ù…Ø­Ø¸ÙˆØ±. Ù‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù† Ø§Ù„Ù…Ù†ØµØ© Ù‚Ø¯ Ù‚Ø§Ù…Øª Ø¨ØªØ¹Ø·ÙŠÙ„ Ø§Ù„Ø­Ø³Ø§Ø¨.")
                    elif status_class == "not-found":
                        st.warning("Ø§Ù„Ø­Ø³Ø§Ø¨ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ø£Ùˆ ØªÙ… Ø­Ø°ÙÙ‡. ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù….")
                    else:
                        st.info("Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† ØªØ­Ø¯ÙŠØ¯ Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø³Ø§Ø¨ Ø¨Ø¯Ù‚Ø©. ÙŠÙ…ÙƒÙ†Ùƒ Ø²ÙŠØ§Ø±Ø© Ø§Ù„Ø±Ø§Ø¨Ø· Ù„Ù„ØªØ­Ù‚Ù‚ ÙŠØ¯ÙˆÙŠÙ‹Ø§.")
            else:
                st.error("âš ï¸ Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ù…Ø³ØªØ®Ø¯Ù… ØµØ­ÙŠØ­ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø¯Ø®Ù„")
    else:
        st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø±Ø§Ø¨Ø· Ø§Ù„Ø­Ø³Ø§Ø¨ Ø£Ùˆ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£ÙˆÙ„Ø§Ù‹")

# ØªØ°ÙŠÙŠÙ„ Ø§Ù„ØµÙØ­Ø©
st.markdown("---")
st.markdown("""
<p style="text-align: center; color: #666; font-size: 0.9rem;">
    Ø£Ø¯Ø§Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª | ØªØ¹Ù…Ù„ Ø¨ÙØ­Øµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙØ¹Ù„ÙŠ Ù„Ù„ØµÙØ­Ø§Øª
</p>
""", unsafe_allow_html=True)
